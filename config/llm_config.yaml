# LLM 配置
# 注意：所有 LLM 相关配置都应该在此文件中定义
# base_url 可以使用环境变量 ${OLLAMA_BASE_URL}，如果环境变量不存在则使用默认值

llm:
  provider: "ollama"
  base_url: "${OLLAMA_BASE_URL}"  # 从 .env 读取，默认: http://localhost:11434
  model: "gpt-oss:20b"  # 可选: deepseek-r1:8b, qwen2.5:14b, llama3.1:8b 等
  temperature: 0.7
  max_tokens: 8000
  timeout: 120

# Embedding 配置
embedding:
  provider: "ollama"
  base_url: "${OLLAMA_BASE_URL}"  # 从 .env 读取，默认: http://localhost:11434
  model: "nomic-embed-text"  # Ollama 嵌入模型
